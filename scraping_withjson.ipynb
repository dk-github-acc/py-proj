{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crawling and scraping midas-iiitd webpg\n",
    "\"\"\"Storing content and image urls of midas web pages in .txt files and .json files\"\"\"\n",
    "import json\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from urllib.request import urlopen \n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class Web_urls(object):\n",
    "    def __init__(self,url):\n",
    "        self.wlink = requests.get(url)\n",
    "        print(self.wlink.content)\n",
    "\n",
    "    def content_bs(self):\n",
    "        print(\"\\n\\n\\n\\nafter using Beautifulsoup library,the parsed html content is:\\n\\n\\n\")\n",
    "        self.soup = BeautifulSoup(self.wlink.content,'html5lib')\n",
    "        print(self.soup.prettify)\n",
    "        \n",
    "        \n",
    "    def url_images(self):   \n",
    "        print(\"\\n\\n\\n\\nThe list of images(with <img>) in web page are:\\n\\n\\n\")\n",
    "        images=self.soup.find_all('img')\n",
    "        print(images)\n",
    "        \n",
    "        \n",
    "        print(\"\\n\\n\")\n",
    "        for im in images:\n",
    "            print(im['src']+'\\n')\n",
    "        \n",
    "\n",
    "        \n",
    "    \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=Web_urls(\"http://midas.iiitd.edu.in/\")                       #first page-research\n",
    "c.content_bs()\n",
    "c.url_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpgtext=c.soup.findAll(\"p\")\n",
    "fpgtext_a=c.soup.findAll(\"a\")\n",
    "print(fpgtext,\"\\n\\n\\n\\n\\n\")\n",
    "print(\"\\n\\n\\n\\n\\n\",fpgtext_a,\"\\n\\n\\n\\n\\n\")\n",
    "for txt in fpgtext :\n",
    "    print(txt.get_text())\n",
    "for txt_a in fpgtext_a:\n",
    "    print(txt_a.get_text())\n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"fpge.txt\",\"w\",encoding = \"UTF-8\") as f:\n",
    "    for txt in fpgtext :\n",
    "        f.write(txt.get_text())\n",
    "        f.write(\"\\n\\n\")\n",
    "    f.write(\"\\n\"*3)\n",
    "    for txt in fpgtext_a :\n",
    "        f.write(txt.get_text())\n",
    "        f.write(\"\\n\\n\")\n",
    "with open(\"fpge.txt\",\"r\",encoding = \"UTF-8\") as f:\n",
    "    fpg=f.read()\n",
    "    \n",
    "with open(\"fpge.json\",\"w\",encoding = \"UTF-8\") as f:\n",
    "    json.dump(fpg,f)\n",
    "\n",
    "with open(\"imgfpg.txt\",'w') as fi:\n",
    "    images=c.soup.findAll(\"img\")\n",
    "    for im in images :\n",
    "        #print(im['src']+\"\\n\")\n",
    "        fi.write(im['src']+\"\\n\\n\")\n",
    "        \n",
    "with open(\"imgurl.txt\",\"r\",encoding = \"UTF-8\") as f:\n",
    "    img_urls = f.read()\n",
    "    \n",
    "with open(\"imgfpg.json\",\"w\") as f:\n",
    "    json.dump(img_urls ,f,indent=2)\n",
    " \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=Web_urls(\"http://midas.iiitd.edu.in/projects/\")                  #projects page\n",
    "p.content_bs()\n",
    "p.url_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pro_text=p.soup.findAll(\"p\")\n",
    "pro_text_a=p.soup.findAll(\"a\")\n",
    "print(pro_text,\"\\n\\n\\n\\n\\n\")\n",
    "print(\"\\n\\n\\n\\n\\n\",pro_text_a,\"\\n\\n\\n\\n\\n\")\n",
    "for txt in pro_text :\n",
    "    print(txt.get_text())\n",
    "for txt_a in pro_text_a:\n",
    "    print(txt_a.get_text())\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"proj.txt\",\"w\",encoding = \"UTF-8\") as f:\n",
    "    for txt in pro_text :\n",
    "        f.write(txt.get_text())\n",
    "        f.write(\"\\n\\n\")\n",
    "    f.write(\"\\n\"*3)\n",
    "    for txt in pro_text_a :\n",
    "        f.write(txt.get_text())\n",
    "        f.write(\"\\n\\n\")\n",
    "with open(\"proj.txt\",\"r\",encoding = \"UTF-8\") as f:\n",
    "    fpg=f.read()\n",
    "    \n",
    "with open(\"proj.json\",\"w\",encoding = \"UTF-8\") as f:\n",
    "    json.dump(fpg,f)\n",
    "\n",
    "with open(\"projimgurl.txt\",'w') as fi:\n",
    "    images=p.soup.findAll(\"img\")\n",
    "    for im in images :\n",
    "        #print(im['src']+\"\\n\")\n",
    "        fi.write(im['src']+\"\\n\\n\")\n",
    "        \n",
    "with open(\"projimgurl.txt\",\"r\",encoding = \"UTF-8\") as f:\n",
    "    img_urls = f.read()\n",
    "    \n",
    "with open(\"projimgurl.json\",\"w\") as f:\n",
    "    json.dump(img_urls ,f,indent=2)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=Web_urls(\"http://midas.iiitd.edu.in/team/\")              #team page\n",
    "t.content_bs()\n",
    "t.url_images()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_text=t.soup.findAll(\"p\")\n",
    "team_text_a=t.soup.findAll(\"a\")\n",
    "print(team_text,\"\\n\\n\\n\\n\\n\")\n",
    "print(\"\\n\\n\\n\\n\\n\",pro_text_a,\"\\n\\n\\n\\n\\n\")\n",
    "for index,txt in enumerate(team_text) :\n",
    "    print(index ,txt.get_text())\n",
    "for txt_a in team_text_a:\n",
    "    print(txt_a.get_text())\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"team.txt\",\"w\",encoding = \"UTF-8\") as f:\n",
    "    for txt in team_text :\n",
    "        f.write(txt.get_text())\n",
    "        f.write(\"\\n\\n\")\n",
    "    f.write(\"\\n\"*3)\n",
    "    for txt in team_text_a :\n",
    "        f.write(txt.get_text())\n",
    "        f.write(\"\\n\\n\")\n",
    "with open(\"team.txt\",\"r\",encoding = \"UTF-8\") as f:\n",
    "    fpg=f.read()\n",
    "    \n",
    "with open(\"teamim.json\",\"w\",encoding = \"UTF-8\") as f:\n",
    "    json.dump(fpg,f)\n",
    "\n",
    "with open(\"teamimgurl.txt\",'w') as fi:\n",
    "    images=t.soup.findAll(\"img\")\n",
    "    for im in images :\n",
    "        #print(im['src']+\"\\n\")\n",
    "        fi.write(im['src']+\"\\n\\n\")\n",
    "        \n",
    "with open(\"teamimgurl.txt\",\"r\",encoding = \"UTF-8\") as f:\n",
    "    img_urls = f.read()\n",
    "    \n",
    "with open(\"teamimgurl.json\",\"w\") as f:\n",
    "    json.dump(img_urls ,f,indent=2)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prs=Web_urls(\"http://midas.iiitd.edu.in/papers/\")                         #papers page\n",
    "prs.content_bs()\n",
    "prs.url_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_text_a=prs.soup.findAll(\"a\")\n",
    "print(\"\\n\\n\\n\\n\\n\",paper_text_a,\"\\n\\n\\n\\n\\n\")\n",
    "for txt_a in paper_text_a:\n",
    "    print(txt_a.get_text())\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"paper.txt\",\"w\",encoding = \"UTF-8\") as f:\n",
    "    for txt in paper_text_a:\n",
    "        f.write(txt.get_text())\n",
    "        f.write(\"\\n\\n\")\n",
    "with open(\"paper.txt\",\"r\",encoding = \"UTF-8\") as f:\n",
    "    fpg=f.read()\n",
    "    \n",
    "with open(\"paper.json\",\"w\",encoding = \"UTF-8\") as f:\n",
    "    json.dump(fpg,f,indent=10)\n",
    "\n",
    "with open(\"paperimgurl.txt\",'w') as fi:\n",
    "    images=prs.soup.findAll(\"img\")\n",
    "    for im in images :\n",
    "        #print(im['src']+\"\\n\")\n",
    "        fi.write(im['src']+\"\\n\\n\")\n",
    "        \n",
    "with open(\"paperimgurl.txt\",\"r\",encoding = \"UTF-8\") as f:\n",
    "    img_urls = f.read()\n",
    "    \n",
    "with open(\"paperimgurl.json\",\"w\") as f:\n",
    "    json.dump(img_urls ,f,indent=2)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=Web_urls(\"http://midas.iiitd.edu.in/blog/\")                                #blogs page\n",
    "b.content_bs()\n",
    "b.url_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blog_text=b.soup.findAll(\"p\")\n",
    "blog_text_a=b.soup.findAll(\"a\")\n",
    "print(blog_text,\"\\n\\n\\n\\n\\n\")\n",
    "print(\"\\n\\n\\n\\n\\n\",blog_text_a,\"\\n\\n\\n\\n\\n\")\n",
    "for txt in blog_text :\n",
    "    print(\"---  \",txt.get_text())\n",
    "for txt_a in blog_text_a:\n",
    "    print(txt_a.get_text())\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"blog.txt\",\"w\",encoding = \"UTF-8\") as f:\n",
    "    for index,txt in enumerate(blog_text) :\n",
    "        f.write(txt.get_text())\n",
    "        f.write(\"\\n\\n\")\n",
    "    f.write(\"\\n\"*3)\n",
    "    for txt in blog_text_a :\n",
    "        f.write(txt.get_text())\n",
    "        f.write(\"\\n\\n\")\n",
    "with open(\"blog.txt\",\"r\",encoding = \"UTF-8\") as f:\n",
    "    fpg=f.read()\n",
    "    \n",
    "with open(\"blog.json\",\"w\",encoding = \"UTF-8\") as f:\n",
    "    json.dump(fpg,f)\n",
    "\n",
    "with open(\"blogimgurl.txt\",'w') as fi:\n",
    "    images=b.soup.findAll(\"img\")\n",
    "    for im in images :\n",
    "        #print(im['src']+\"\\n\")\n",
    "        fi.write(im['src']+\"\\n\\n\")\n",
    "        \n",
    "with open(\"blogimgurl.txt\",\"r\",encoding = \"UTF-8\") as f:\n",
    "    img_urls = f.read()\n",
    "    \n",
    "with open(\"blogimgurl.json\",\"w\") as f:\n",
    "    json.dump(img_urls ,f,indent=2)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op=Web_urls(\"http://midas.iiitd.edu.in/openings/\")                      #openings page\n",
    "op.content_bs()\n",
    "op.url_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_text=op.soup.findAll(\"p\")\n",
    "op_text_a=op.soup.findAll(\"a\")\n",
    "print(\"\\n\\n\\n\\n\\n\",op_text_a,\"\\n\\n\\n\\n\\n\")\n",
    "print(blog_text,\"\\n\\n\\n\\n\\n\")\n",
    "for txt in op_text :\n",
    "    print(\"---  \",txt.get_text())\n",
    "for txt_a in op_text_a:\n",
    "    print(txt_a.get_text())\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"openin.txt\",\"w\",encoding = \"UTF-8\") as f:\n",
    "    for txt in op_text :\n",
    "        f.write(txt.get_text())\n",
    "        f.write(\"\\n\\n\")\n",
    "    f.write(\"\\n\"*3)\n",
    "    for txt in op_text_a :\n",
    "        f.write(txt.get_text())\n",
    "        f.write(\"\\n\\n\")\n",
    "with open(\"openin.txt\",\"r\",encoding = \"UTF-8\") as f:\n",
    "    fpg=f.read()\n",
    "    \n",
    "with open(\"openin.json\",\"w\",encoding = \"UTF-8\") as f:\n",
    "    json.dump(fpg,f)\n",
    "\n",
    "with open(\"openinimgurl.txt\",'w') as fi:\n",
    "    images=op.soup.findAll(\"img\")\n",
    "    for im in images :\n",
    "        #print(im['src']+\"\\n\")\n",
    "        fi.write(im['src']+\"\\n\\n\")\n",
    "        \n",
    "with open(\"openinimgurl.txt\",\"r\",encoding = \"UTF-8\") as f:\n",
    "    img_urls = f.read()\n",
    "    \n",
    "with open(\"openinimgurl.json\",\"w\") as f:\n",
    "    json.dump(img_urls ,f,indent=2)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=Web_urls(\"http://midas.iiitd.edu.in/news/\")                                    #news page\n",
    "n.content_bs()\n",
    "n.url_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_text=n.soup.findAll(\"p\")\n",
    "news_text_p_a=n.soup.p.findAll(\"a\")\n",
    "news_text_a=n.soup.div.findAll(\"a\")\n",
    "print(\"\\n\\n\\n\\n\\n\",news_text_a,\"\\n\\n\\n\\n\\n\")\n",
    "print(news_text,\"\\n\\n\\n\\n\\n\")\n",
    "for txt_a in news_text_a:\n",
    "    print(txt_a.get_text())\n",
    "print(\"\\n\"*5)\n",
    "for txt in news_text :\n",
    "    print(\"---  \",txt.get_text())\n",
    "for txt_a in news_text_p_a:\n",
    "    print(txt_a.get_text())\n",
    "\n",
    "with open(\"newsimgurl.txt\",'w') as fi:\n",
    "    images=n.soup.findAll(\"img\")\n",
    "    for im in images :\n",
    "        #print(im['src']+\"\\n\")\n",
    "        fi.write(im['src']+\"\\n\\n\")\n",
    "        \n",
    "with open(\"newsimgurl.txt\",\"r\",encoding = \"UTF-8\") as f:\n",
    "    img_urls = f.read()\n",
    "    \n",
    "with open(\"newsimgurl.json\",\"w\") as f:\n",
    "    json.dump(img_urls ,f,indent=2)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"news.txt\",\"w\",encoding = \"UTF-8\") as f:\n",
    "    for txt in news_text:\n",
    "        f.write(txt.get_text())\n",
    "        f.write(\"\\n\\n\")\n",
    "    f.write(\"\\n\"*3)\n",
    "    for txt in news_text_p_a :\n",
    "        f.write(txt.get_text())\n",
    "        f.write(\"\\n\\n\")\n",
    "    f.write(\"\\n\"*3)\n",
    "    for txt in news_text_a :\n",
    "        f.write(txt.get_text())\n",
    "        f.write(\"\\n\\n\")\n",
    "with open(\"news.txt\",\"r\",encoding = \"UTF-8\") as f:\n",
    "    fpg=f.read()\n",
    "    \n",
    "with open(\"news.json\",\"w\",encoding = \"UTF-8\") as f:\n",
    "    json.dump(fpg,f)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e=Web_urls(\"http://midas.iiitd.edu.in/events/\")                               #events page\n",
    "e.content_bs()\n",
    "e.url_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eve_text_a=e.soup.findAll(\"a\")\n",
    "eve_text=e.soup.findAll(\"p\")\n",
    "\n",
    "print(\"\\n\\n\\n\\n\\n\",eve_text_a,\"\\n\\n\\n\\n\\n\")\n",
    "print(eve_text,\"\\n\\n\\n\\n\\n\")\n",
    "for txt_a in eve_text_a:\n",
    "    print(txt_a.get_text())\n",
    "print(\"\\n\"*5)\n",
    "for txt in eve_text :\n",
    "    print(\"---  \",txt.get_text())\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"events.txt\",\"w\",encoding = \"UTF-8\") as f:\n",
    "    for txt in eve_text:\n",
    "        f.write(txt.get_text())\n",
    "        f.write(\"\\n\\n\")\n",
    "    f.write(\"\\n\"*3)\n",
    "    for txt in eve_text_a :\n",
    "        f.write(txt.get_text())\n",
    "        f.write(\"\\n\\n\")\n",
    "        \n",
    "with open(\"events.txt\",\"r\",encoding = \"UTF-8\") as f:\n",
    "    fpg=f.read()\n",
    "    \n",
    "with open(\"events.json\",\"w\",encoding = \"UTF-8\") as f:\n",
    "    json.dump(fpg,f)\n",
    "\n",
    "with open(\"eventsimgurl.txt\",'w') as fi:\n",
    "    images=e.soup.findAll(\"img\")\n",
    "    for im in images :\n",
    "        #print(im['src']+\"\\n\")\n",
    "        fi.write(im['src']+\"\\n\\n\")\n",
    "        \n",
    "with open(\"eventsimgurl.txt\",\"r\",encoding = \"UTF-8\") as f:\n",
    "    img_urls = f.read()\n",
    "    \n",
    "with open(\"eventsimgurl.json\",\"w\") as f:\n",
    "    json.dump(img_urls ,f,indent=2)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
